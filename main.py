import streamlit as st
from audio_recorder_streamlit import audio_recorder
import plotly.express as px
import joblib
# from io import BytesIO
# from pydub import AudioSegment
# import speech_recognition as sr

import STT
from time import time, sleep
import pandas as pd
from PIL import Image

st.set_page_config(layout="wide")
empty1,con1,empty2 = st.columns([0.3,1.0,0.3])
empyt1,con2,con3,empty2 = st.columns([0.3,0.5,0.5,0.3])
# empyt1,con4,empty2 = st.columns([0.3,1.0,0.3])
# empyt1,con5,con6,empty2 = st.columns([0.3,0.5,0.5,0.3])


def speech_to_text(DIR: str):
    id = STT.BitoPost(DIR)
    sleep(5)
    result = STT.BitoGet(id)
    return result

def load_image(image_file):
    img = Image.open(image_file)
    return img

def main():
    # with empty1 : 
    #     empty()
    # with empty2:
    #     empty()
    if 'text_data' not in st.session_state or 'prob' not in st.session_state :
        st.session_state['text_data'] = ''
        st.session_state['prob'] = ''

    with con1 :
        img = load_image('yellow.png')
        st.image(img)
        st.title('ğŸ‘®ë³´ì´ìŠ¤í”¼ì‹± ì¡ì•„ë¼ğŸ‘®')
        audio_bytes = audio_recorder(
        text="Click to record",
        pause_threshold=100.0 # 100ì´ˆ ëŠ˜ë ¤ì•¼í• ë“¯..?
        # recording_color="#6aa36f",
        # neutral_color="#909090",
        # icon_name="volumne",
        # icon_size="3x",
    )
        if audio_bytes:
            with open("audio.wav", "wb") as f:
                f.write(audio_bytes)

            result_dict = {}
            st.write('stt ì§„í–‰ ì¤‘')
            st.session_state.text_data = speech_to_text("audio.wav")


            st.write('call classification model & encoder')
            model = joblib.load('best_f1_model.pkl')
            encoder = joblib.load('best_tfvec.pkl')
            

            slice_num = 5 #slice í•  ê¸€ì ìˆ˜
            for i in range(round(len(st.session_state.text_data)/slice_num)):
                text = st.session_state.text_data[ : slice_num*(1+i)]
                array = model.predict_proba(encoder.transform([text]))
                st.session_state.prob = array[0][0]
                result_dict[slice_num*(1+i)] = 1 - st.session_state.prob #probëŠ” 0ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ ë³´ì´ìŠ¤ í”¼ì‹±ì„?


            df = pd.DataFrame.from_dict([result_dict]).transpose().reset_index()
            df.columns = ['text_length', 'prob']
            fig = px.area(df, x='text_length', y='prob', markers = True)
            
        # tab1, tab2 = st.tabs(["output text", "plot"])
        with con2:
            audio_file = open("audio.wav", 'rb')
            st.audio( audio_file.read() , format='audio/wav')

            st.markdown(f'ê²°ê³¼: {st.session_state.text_data}')
            st.text(round(1-st.session_state.prob,2))

        with con3:
            st.plotly_chart(fig, theme=None)



if __name__ == "__main__":
    main()